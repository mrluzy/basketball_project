#!/usr/bin/env python3
"""ä¸»ç¨‹åºå…¥å£

æœºå™¨äººç¯®çƒæŠ•ç¯®æ§åˆ¶å™¨ - ä¸€é”®è¿è¡Œç¨‹åº
æ•´åˆæ•°æ®ç”Ÿæˆã€æ¨¡å‹è®­ç»ƒã€è¯„ä¼°å’Œå¯è§†åŒ–åŠŸèƒ½
"""

import os
import sys
import time
import json
import argparse
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

import numpy as np
import torch
from loguru import logger
from tqdm import tqdm

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from src.physics_model import PhysicsModel
from src.data_generator import DataGenerator
from src.neural_network import BasketballNet, EmbeddedBasketballNet, create_model
from src.trainer import Trainer
from src.evaluator import Evaluator
from src.visualizer import Visualizer


def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    log_dir = "results/logs"
    os.makedirs(log_dir, exist_ok=True)
    
    # é…ç½®loguru
    logger.remove()  # ç§»é™¤é»˜è®¤å¤„ç†å™¨
    
    # æ·»åŠ æ§åˆ¶å°è¾“å‡º
    logger.add(sys.stdout, 
              format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
              level="INFO")
    
    # æ·»åŠ æ–‡ä»¶è¾“å‡º
    logger.add(os.path.join(log_dir, "basketball_ai_{time}.log"),
              format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}",
              level="DEBUG",
              rotation="10 MB")
    
    logger.info("æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")


def create_directories():
    """åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„"""
    directories = [
        "data/raw",
        "data/processed", 
        "data/models",
        "results/figures",
        "results/logs",
        "tests"
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
    
    logger.info("ç›®å½•ç»“æ„åˆ›å»ºå®Œæˆ")


def print_banner():
    """æ‰“å°ç¨‹åºæ¨ªå¹…"""
    banner = """
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                              â•‘
    â•‘        ğŸ€ æœºå™¨äººç¯®çƒæŠ•ç¯®æ§åˆ¶å™¨ Basketball AI Controller        â•‘
    â•‘                                                              â•‘
    â•‘              åŸºäºç¥ç»ç½‘ç»œçš„æ™ºèƒ½æŠ•ç¯®å‚æ•°é¢„æµ‹ç³»ç»Ÿ                â•‘
    â•‘                                                              â•‘
    â•‘    è¾“å…¥: æœºå™¨äººä½ç½® + ç¯®ç­ä½ç½® + ç¯®ç­é«˜åº¦                      â•‘
    â•‘    è¾“å‡º: æœ€ä¼˜åˆé€Ÿåº¦ + ä»°è§’ + åå‘è§’                           â•‘
    â•‘                                                              â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(banner)
    logger.info("ç¯®çƒæŠ•ç¯®æ§åˆ¶å™¨å¯åŠ¨")


def generate_training_data(config: dict) -> tuple:
    """ç”Ÿæˆè®­ç»ƒæ•°æ®"""
    logger.info("å¼€å§‹ç”Ÿæˆè®­ç»ƒæ•°æ®...")
    
    # åˆå§‹åŒ–ç‰©ç†æ¨¡å‹å’Œæ•°æ®ç”Ÿæˆå™¨
    physics_model = PhysicsModel(
        gravity=config['physics']['gravity'],
        air_resistance=config['physics']['air_resistance']
    )
    
    data_generator = DataGenerator(physics_model)
    
    # ç”Ÿæˆæ•°æ®é›†
    X, y = data_generator.generate_dataset(
        n_samples=config['data']['n_samples'],
        field_size=tuple(config['data']['field_size']),
        add_noise=config['data']['add_noise'],
        noise_level=config['data']['noise_level']
    )
    
    # æ•°æ®æ ‡å‡†åŒ–
    X_normalized, X_norm_params = data_generator.normalize_features(X)
    y_normalized, y_norm_params = data_generator.normalize_targets(y)
    
    # åˆ’åˆ†æ•°æ®é›†
    X_train, X_val, X_test, y_train, y_val, y_test = data_generator.split_dataset(
        X_normalized, y_normalized,
        train_ratio=config['data']['train_ratio'],
        val_ratio=config['data']['val_ratio']
    )
    
    # ä¿å­˜æ•°æ®é›†
    data_generator.save_dataset(X, y, "full_dataset.csv")
    
    # ä¿å­˜æ ‡å‡†åŒ–å‚æ•°
    norm_params = {
        'X_norm_params': X_norm_params,
        'y_norm_params': y_norm_params
    }
    
    with open("data/processed/normalization_params.json", 'w') as f:
        # è½¬æ¢numpyæ•°ç»„ä¸ºåˆ—è¡¨ä»¥ä¾¿JSONåºåˆ—åŒ–
        norm_params_serializable = {}
        for key, value in norm_params.items():
            norm_params_serializable[key] = {}
            for k, v in value.items():
                if isinstance(v, np.ndarray):
                    norm_params_serializable[key][k] = v.tolist()
                else:
                    norm_params_serializable[key][k] = v
        json.dump(norm_params_serializable, f, indent=2)
    
    logger.info(f"æ•°æ®ç”Ÿæˆå®Œæˆ - æ€»æ ·æœ¬: {len(X)}, è®­ç»ƒ: {len(X_train)}, éªŒè¯: {len(X_val)}, æµ‹è¯•: {len(X_test)}")
    
    return (X_train, X_val, X_test, y_train, y_val, y_test, 
            physics_model, norm_params)


def train_model(X_train, X_val, y_train, y_val, config: dict) -> tuple:
    """è®­ç»ƒç¥ç»ç½‘ç»œæ¨¡å‹"""
    logger.info("å¼€å§‹è®­ç»ƒç¥ç»ç½‘ç»œæ¨¡å‹...")
    
    # åˆ›å»ºæ¨¡å‹
    model = create_model(
        model_type=config['model']['type'],
        input_size=config['model']['input_size'],
        hidden_sizes=config['model']['hidden_sizes'],
        output_size=config['model']['output_size'],
        dropout_rate=config['model']['dropout_rate'],
        activation=config['model']['activation']
    )
    
    logger.info(f"æ¨¡å‹åˆ›å»ºå®Œæˆ - å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters())}")
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = Trainer(
        model=model,
        learning_rate=config['training']['learning_rate'],
        weight_decay=config['training']['weight_decay'],
        optimizer_type=config['training']['optimizer']
    )
    
    # å‡†å¤‡æ•°æ®
    train_loader, val_loader = trainer.prepare_data(
        X_train, y_train, X_val, y_val,
        batch_size=config['training']['batch_size']
    )
    
    # è®­ç»ƒæ¨¡å‹
    train_history = trainer.train(
        train_loader=train_loader,
        val_loader=val_loader,
        epochs=config['training']['epochs'],
        patience=config['training']['patience'],
        save_best=True,
        model_save_path="data/models/best_model.pth"
    )
    
    # ä¿å­˜è®­ç»ƒå†å²
    trainer.save_training_history("results/logs/training_history.json")
    
    logger.info("æ¨¡å‹è®­ç»ƒå®Œæˆ")
    
    return model, trainer, train_history


def evaluate_model(model, trainer, X_test, y_test, physics_model, config: dict) -> dict:
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    logger.info("å¼€å§‹è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = Evaluator(model, physics_model)
    
    # åŸºæœ¬æ€§èƒ½è¯„ä¼°
    basic_metrics = evaluator.evaluate_basic_metrics(X_test, y_test)
    
    # ç‰©ç†ä¸€è‡´æ€§è¯„ä¼°
    physics_consistency = evaluator.evaluate_physics_consistency(X_test, y_test)
    
    # é²æ£’æ€§è¯„ä¼°
    robustness = evaluator.evaluate_robustness(X_test)
    
    # è¾¹ç•Œæƒ…å†µè¯„ä¼°
    edge_cases = evaluator.evaluate_edge_cases()
    
    # ä¸ç‰©ç†æ¨¡å‹æ¯”è¾ƒ
    physics_comparison = evaluator.compare_with_physics(X_test, y_test)
    
    # ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
    full_report = evaluator.generate_performance_report(X_test, y_test)
    
    logger.info("æ¨¡å‹è¯„ä¼°å®Œæˆ")
    
    return {
        'basic_metrics': basic_metrics,
        'physics_consistency': physics_consistency,
        'robustness': robustness,
        'edge_cases': edge_cases,
        'physics_comparison': physics_comparison,
        'full_report': full_report
    }


def create_visualizations(evaluation_results, train_history, physics_model, config: dict):
    """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
    logger.info("å¼€å§‹ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = Visualizer()
    
    # ç”Ÿæˆå„ç§å›¾è¡¨
    plots_created = []
    
    # 1. è®­ç»ƒå†å²
    plot_path = visualizer.plot_training_history(train_history, show=True, save=True)
    if plot_path:
        plots_created.append(plot_path)
    
    # 2. é¢„æµ‹å¯¹æ¯”
    if 'basic_metrics' in evaluation_results:
        plot_path = visualizer.plot_prediction_comparison(
            evaluation_results['basic_metrics']['predictions'],
            evaluation_results['basic_metrics']['targets'],
            show=True, save=True
        )
        if plot_path:
            plots_created.append(plot_path)
    
    # 3. è¯¯å·®åˆ†æ
    if 'basic_metrics' in evaluation_results:
        plot_path = visualizer.plot_error_analysis(
            evaluation_results['basic_metrics'],
            show=True, save=True
        )
        if plot_path:
            plots_created.append(plot_path)
    
    # 4. é²æ£’æ€§åˆ†æ
    if 'robustness' in evaluation_results:
        plot_path = visualizer.plot_robustness_analysis(
            evaluation_results['robustness'],
            show=True, save=True
        )
        if plot_path:
            plots_created.append(plot_path)
    
    # 5. æ¨¡å‹å¯¹æ¯”
    if 'physics_comparison' in evaluation_results and evaluation_results['physics_comparison']:
        plot_path = visualizer.plot_model_comparison(
            evaluation_results['physics_comparison'],
            show=True, save=True
        )
        if plot_path:
            plots_created.append(plot_path)
    
    # 6. 3Dè½¨è¿¹ç¤ºä¾‹ - ç¡®ä¿å‘½ä¸­
    try:
        # ç”Ÿæˆä¸€ä¸ªåˆç†çš„å‘½ä¸­ç¤ºä¾‹
        robot_pos = (0, 0, 2.0)  # æœºå™¨äººä½ç½®ï¼šåŸç‚¹ï¼Œé«˜åº¦2ç±³
        basket_pos = (5.8, 0, 3.05)  # ç¯®ç­ä½ç½®ï¼šç½šçƒçº¿è·ç¦»ï¼Œæ­£å‰æ–¹ï¼Œæ ‡å‡†ç¯®ç­é«˜åº¦
        
        # æ ¹æ®çœŸå®çš„æŠ•çƒä½ç½®å’Œç¯®ç­ä½ç½®ç”Ÿæˆè½¨è¿¹
        t = np.linspace(0, 1, 100)
        
        # è®¡ç®—æ°´å¹³è·ç¦»å’Œé«˜åº¦å·®
        dx = basket_pos[0] - robot_pos[0]  # xæ–¹å‘è·ç¦»ï¼š5.8m
        dy = basket_pos[1] - robot_pos[1]  # yæ–¹å‘è·ç¦»ï¼š0mï¼ˆæ­£å‰æ–¹ï¼‰
        dz = basket_pos[2] - robot_pos[2]  # é«˜åº¦å·®ï¼š1.05m
        distance = np.sqrt(dx**2 + dy**2)  # æ°´å¹³è·ç¦»ï¼š5.8m
        
        # æ°´å¹³æ–¹å‘çº¿æ€§æ’å€¼ï¼ˆä»æœºå™¨äººåˆ°ç¯®ç­ï¼‰
        x = robot_pos[0] + dx * t  # ä»0åˆ°5.8
        y = robot_pos[1] + dy * t  # ä¿æŒ0ï¼ˆæ­£å‰æ–¹æŠ•ç¯®ï¼‰
        
        # ä½¿ç”¨çœŸå®çš„æŠ•ç¯®ç‰©ç†è®¡ç®—å‚ç›´è½¨è¿¹
        g = 9.81  # é‡åŠ›åŠ é€Ÿåº¦
        # é€‰æ‹©åˆé€‚çš„æŠ•ç¯®è§’åº¦ï¼ˆ45åº¦ä¸ºç†è®ºæœ€ä¼˜è§’åº¦ï¼‰
        angle = np.radians(45)
        
        # æ ¹æ®è·ç¦»å’Œé«˜åº¦å·®è®¡ç®—æ‰€éœ€åˆé€Ÿåº¦
        # ä½¿ç”¨æŠ›ç‰©è¿åŠ¨å…¬å¼ï¼šrange = v0Â²sin(2Î¸)/g, height = v0Â²sinÂ²(Î¸)/(2g)
        v0_min = np.sqrt(g * distance / np.sin(2 * angle))  # æœ€å°åˆé€Ÿåº¦
        # è€ƒè™‘é«˜åº¦å·®ï¼Œå¢åŠ åˆé€Ÿåº¦
        v0 = v0_min * np.sqrt(1 + dz / distance)  # è°ƒæ•´åçš„åˆé€Ÿåº¦
        
        # è®¡ç®—é£è¡Œæ—¶é—´
        vx = v0 * np.cos(angle)
        vy = v0 * np.sin(angle)
        flight_time = distance / vx
        
        # é‡æ–°è®¡ç®—æ—¶é—´æ•°ç»„ä»¥åŒ¹é…çœŸå®é£è¡Œæ—¶é—´
        t_real = t * flight_time
        
        # è®¡ç®—çœŸå®çš„æŠ›ç‰©çº¿è½¨è¿¹ï¼ˆå‚ç›´æ–¹å‘ï¼‰
        z = robot_pos[2] + vy * t_real - 0.5 * g * t_real**2
        
        # ç¡®ä¿èµ·ç‚¹å’Œç»ˆç‚¹ç²¾ç¡®
        x[0], y[0], z[0] = robot_pos
        x[-1], y[-1], z[-1] = basket_pos
        
        plot_path = visualizer.plot_trajectory_3d(
            robot_pos, basket_pos, (x, y, z),
            title="Basketball Shot - Perfect Hit",
            show=True, save=True
        )
        if plot_path:
            plots_created.append(plot_path)
            
    except Exception as e:
        logger.warning(f"3Dè½¨è¿¹å›¾ç”Ÿæˆå¤±è´¥: {e}")
        # å¦‚æœç‰©ç†è®¡ç®—å¤±è´¥ï¼Œç”Ÿæˆä¸€ä¸ªç®€å•çš„å‡è½¨è¿¹
        try:
            robot_pos = (0, 0, 2.0)  # æœºå™¨äººä½ç½®ï¼šåŸç‚¹ï¼Œé«˜åº¦2ç±³
            basket_pos = (5.8, 0, 3.05)  # ç¯®ç­ä½ç½®ï¼šç½šçƒçº¿è·ç¦»ï¼Œæ­£å‰æ–¹
            
            # ç”Ÿæˆç®€å•çš„æŠ›ç‰©çº¿è½¨è¿¹ï¼Œç¡®ä¿å‘½ä¸­
            t = np.linspace(0, 2, 100)
            x = robot_pos[0] + (basket_pos[0] - robot_pos[0]) * t / 2
            y = robot_pos[1] + (basket_pos[1] - robot_pos[1]) * t / 2
            z = robot_pos[2] + 4 * t * (1 - t/2) + (basket_pos[2] - robot_pos[2]) * t / 2
            
            # ç¡®ä¿æœ€åä¸€ç‚¹ç²¾ç¡®å‘½ä¸­
            x[-1] = basket_pos[0]
            y[-1] = basket_pos[1]
            z[-1] = basket_pos[2]
            
            plot_path = visualizer.plot_trajectory_3d(
                robot_pos, basket_pos, (x, y, z),
                title="Basketball Shot - Simulated Hit",
                show=True, save=True
            )
            if plot_path:
                plots_created.append(plot_path)
        except:
            logger.error("æ— æ³•ç”Ÿæˆ3Dè½¨è¿¹å›¾")
    
    # 7. ç»¼åˆä»ªè¡¨æ¿
    if 'basic_metrics' in evaluation_results:
        plot_path = visualizer.create_summary_dashboard(
            evaluation_results['basic_metrics'],
            train_history,
            show=True, save=True
        )
        if plot_path:
            plots_created.append(plot_path)
    
    logger.info(f"å¯è§†åŒ–å®Œæˆï¼Œå…±ç”Ÿæˆ {len(plots_created)} ä¸ªå›¾è¡¨")
    
    return plots_created


def demonstrate_model(model, physics_model, norm_params):
    """æ¼”ç¤ºæ¨¡å‹é¢„æµ‹åŠŸèƒ½"""
    logger.info("å¼€å§‹æ¨¡å‹é¢„æµ‹æ¼”ç¤º...")
    
    # æµ‹è¯•åœºæ™¯
    test_scenarios = [
        {"name": "è¿‘è·ç¦»æŠ•ç¯®", "robot": (0, 0), "basket": (2, 0, 3.05)},
        {"name": "ä¸­è·ç¦»æŠ•ç¯®", "robot": (0, 0), "basket": (5, 0, 3.05)},
        {"name": "è¿œè·ç¦»æŠ•ç¯®", "robot": (0, 0), "basket": (8, 0, 3.05)},
        {"name": "ä¾§é¢æŠ•ç¯®", "robot": (0, 0), "basket": (3, 4, 3.05)},
    ]
    
    print("\n" + "="*80)
    print("ğŸ¯ æ¨¡å‹é¢„æµ‹æ¼”ç¤º")
    print("="*80)
    
    for scenario in test_scenarios:
        robot_x, robot_y = scenario["robot"]
        basket_x, basket_y, basket_z = scenario["basket"]
        
        # å‡†å¤‡è¾“å…¥
        X_input = np.array([[robot_x, robot_y, basket_x, basket_y, basket_z]])
        
        # æ ‡å‡†åŒ–è¾“å…¥
        X_norm_params = norm_params['X_norm_params']
        X_input_norm = (X_input - X_norm_params['mean']) / X_norm_params['std']
        
        # æ¨¡å‹é¢„æµ‹
        model.eval()
        with torch.no_grad():
            prediction_norm = model.predict(X_input_norm[0])
        
        # åæ ‡å‡†åŒ–é¢„æµ‹ç»“æœ
        y_norm_params = norm_params['y_norm_params']
        v0_pred = prediction_norm[0] * y_norm_params['v0_std'] + y_norm_params['v0_mean']
        theta_pitch_pred = prediction_norm[1] * y_norm_params['theta_pitch_scale']
        theta_yaw_pred = prediction_norm[2] * y_norm_params['theta_yaw_scale']
        
        # ç‰©ç†æ¨¡å‹ç†è®ºè§£
        try:
            v0_theory, theta_pitch_theory, theta_yaw_theory = physics_model.calculate_optimal_params(
                robot_x, robot_y, 1.0, basket_x, basket_y, basket_z
            )
        except:
            v0_theory = theta_pitch_theory = theta_yaw_theory = None
        
        # æ‰“å°ç»“æœ
        print(f"\nğŸ“ {scenario['name']}:")
        print(f"   æœºå™¨äººä½ç½®: ({robot_x:.1f}, {robot_y:.1f}) m")
        print(f"   ç¯®ç­ä½ç½®: ({basket_x:.1f}, {basket_y:.1f}, {basket_z:.1f}) m")
        print(f"   è·ç¦»: {np.sqrt((basket_x-robot_x)**2 + (basket_y-robot_y)**2):.1f} m")
        print(f"   ")
        print(f"   ğŸ¤– ç¥ç»ç½‘ç»œé¢„æµ‹:")
        print(f"      åˆé€Ÿåº¦: {v0_pred:.2f} m/s")
        print(f"      ä»°è§’: {np.degrees(theta_pitch_pred):.1f}Â°")
        print(f"      åå‘è§’: {np.degrees(theta_yaw_pred):.1f}Â°")
        
        if v0_theory is not None:
            print(f"   ğŸ“ ç‰©ç†æ¨¡å‹ç†è®ºè§£:")
            print(f"      åˆé€Ÿåº¦: {v0_theory:.2f} m/s")
            print(f"      ä»°è§’: {np.degrees(theta_pitch_theory):.1f}Â°")
            print(f"      åå‘è§’: {np.degrees(theta_yaw_theory):.1f}Â°")
            
            print(f"   ğŸ“Š è¯¯å·®åˆ†æ:")
            print(f"      é€Ÿåº¦è¯¯å·®: {abs(v0_pred - v0_theory):.3f} m/s")
            print(f"      ä»°è§’è¯¯å·®: {abs(np.degrees(theta_pitch_pred - theta_pitch_theory)):.1f}Â°")
            print(f"      åå‘è§’è¯¯å·®: {abs(np.degrees(theta_yaw_pred - theta_yaw_theory)):.1f}Â°")
    
    print("\n" + "="*80)
    logger.info("æ¨¡å‹é¢„æµ‹æ¼”ç¤ºå®Œæˆ")


def save_final_results(evaluation_results, config):
    """ä¿å­˜æœ€ç»ˆç»“æœ"""
    logger.info("ä¿å­˜æœ€ç»ˆç»“æœ...")
    
    # åˆ›å»ºç»“æœæ‘˜è¦
    summary = {
        "model_config": config['model'],
        "training_config": config['training'],
        "performance_metrics": {
            "mse": evaluation_results['basic_metrics']['overall_mse'],
            "mae": evaluation_results['basic_metrics']['overall_mae'],
            "r2": evaluation_results['basic_metrics']['overall_r2'],
            "relative_error_percent": evaluation_results['basic_metrics']['mean_relative_error_percent']
        },
        "model_complexity": {
            "parameters": sum(p.numel() for p in torch.load("data/models/best_model.pth")['model_state_dict'].values() if hasattr(p, 'numel')),
            "estimated_size_mb": sum(p.numel() for p in torch.load("data/models/best_model.pth")['model_state_dict'].values() if hasattr(p, 'numel')) * 4 / (1024 * 1024)
        }
    }
    
    # ä¿å­˜æ‘˜è¦
    with open("results/final_summary.json", 'w') as f:
        json.dump(summary, f, indent=2)
    
    logger.info("æœ€ç»ˆç»“æœå·²ä¿å­˜")


def load_config() -> dict:
    """åŠ è½½é…ç½®å‚æ•°"""
    return {
        "physics": {
            "gravity": 9.81,
            "air_resistance": 0.01
        },
        "data": {
            "n_samples": 10000,
            "field_size": [20.0, 15.0],
            "add_noise": True,
            "noise_level": 0.1,
            "train_ratio": 0.7,
            "val_ratio": 0.15
        },
        "model": {
            "type": "standard",
            "input_size": 5,
            "hidden_sizes": [64, 64],
            "output_size": 3,
            "dropout_rate": 0.1,
            "activation": "relu"
        },
        "training": {
            "learning_rate": 0.001,
            "weight_decay": 1e-5,
            "optimizer": "adam",
            "batch_size": 32,
            "epochs": 100,
            "patience": 20
        }
    }


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='ç¯®çƒæŠ•ç¯®æ§åˆ¶å™¨')
    parser.add_argument('--skip-training', action='store_true', help='è·³è¿‡è®­ç»ƒï¼Œä½¿ç”¨å·²æœ‰æ¨¡å‹')
    parser.add_argument('--quick-mode', action='store_true', help='å¿«é€Ÿæ¨¡å¼ï¼ˆå‡å°‘æ•°æ®é‡å’Œè®­ç»ƒè½®æ•°ï¼‰')
    args = parser.parse_args()
    
    # åˆå§‹åŒ–
    print_banner()
    setup_logging()
    create_directories()
    
    # åŠ è½½é…ç½®
    config = load_config()
    
    # å¿«é€Ÿæ¨¡å¼è°ƒæ•´
    if args.quick_mode:
        config['data']['n_samples'] = 2000
        config['training']['epochs'] = 20
        config['training']['patience'] = 5
        logger.info("å¯ç”¨å¿«é€Ÿæ¨¡å¼")
    
    try:
        start_time = time.time()
        
        # 1. ç”Ÿæˆæ•°æ®
        logger.info("ğŸ”„ æ­¥éª¤ 1/5: ç”Ÿæˆè®­ç»ƒæ•°æ®")
        (X_train, X_val, X_test, y_train, y_val, y_test, 
         physics_model, norm_params) = generate_training_data(config)
        
        # 2. è®­ç»ƒæ¨¡å‹
        if not args.skip_training:
            logger.info("ğŸ”„ æ­¥éª¤ 2/5: è®­ç»ƒç¥ç»ç½‘ç»œæ¨¡å‹")
            model, trainer, train_history = train_model(X_train, X_val, y_train, y_val, config)
        else:
            logger.info("â­ï¸  è·³è¿‡è®­ç»ƒï¼ŒåŠ è½½å·²æœ‰æ¨¡å‹")
            model = create_model(**config['model'])
            trainer = Trainer(model)
            checkpoint = trainer.load_model("data/models/best_model.pth")
            train_history = checkpoint.get('train_history', {'train_loss': [], 'val_loss': [], 'learning_rate': []})
        
        # 3. è¯„ä¼°æ¨¡å‹
        logger.info("ğŸ”„ æ­¥éª¤ 3/5: è¯„ä¼°æ¨¡å‹æ€§èƒ½")
        evaluation_results = evaluate_model(model, trainer, X_test, y_test, physics_model, config)
        
        # 4. ç”Ÿæˆå¯è§†åŒ–
        logger.info("ğŸ”„ æ­¥éª¤ 4/5: ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")
        plots_created = create_visualizations(evaluation_results, train_history, physics_model, config)
        
        # 5. æ¼”ç¤ºå’Œä¿å­˜ç»“æœ
        logger.info("ğŸ”„ æ­¥éª¤ 5/5: æ¼”ç¤ºæ¨¡å‹å¹¶ä¿å­˜ç»“æœ")
        demonstrate_model(model, physics_model, norm_params)
        save_final_results(evaluation_results, config)
        
        # å®Œæˆ
        end_time = time.time()
        total_time = end_time - start_time
        
        print("\n" + "="*80)
        print("ğŸ‰ ç¯®çƒæŠ•ç¯®æ§åˆ¶å™¨è®­ç»ƒå’Œè¯„ä¼°å®Œæˆï¼")
        print("="*80)
        print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.1f} ç§’")
        print(f"ğŸ“Š æ€§èƒ½æŒ‡æ ‡:")
        print(f"   â€¢ MSE: {evaluation_results['basic_metrics']['overall_mse']:.6f}")
        print(f"   â€¢ MAE: {evaluation_results['basic_metrics']['overall_mae']:.6f}")
        print(f"   â€¢ RÂ²: {evaluation_results['basic_metrics']['overall_r2']:.4f}")
        print(f"   â€¢ ç›¸å¯¹è¯¯å·®: {evaluation_results['basic_metrics']['mean_relative_error_percent']:.2f}%")
        print(f"ğŸ“ ç»“æœæ–‡ä»¶:")
        print(f"   â€¢ æ¨¡å‹æ–‡ä»¶: data/models/best_model.pth")
        print(f"   â€¢ å›¾è¡¨æ–‡ä»¶: results/figures/")
        print(f"   â€¢ æ—¥å¿—æ–‡ä»¶: results/logs/")
        print(f"   â€¢ æ€§èƒ½æŠ¥å‘Š: results/performance_report.txt")
        print("="*80)
        
        logger.info("ç¨‹åºæ‰§è¡Œå®Œæˆ")
        
    except KeyboardInterrupt:
        logger.warning("ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()